<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="date" content="2021-07-17" />
<link rel="stylesheet" href="https://shijingchang.cn/doc/assets/css/tufte.min.css">
<link href="https://fonts.loli.net/css2?family=Fira+Code&display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://shijingchang.cn/doc/assets/css/extra.css">
<link href="https://cdn.bootcdn.net/ajax/libs/KaTeX/0.16.6/katex.min.css" rel="stylesheet">
<script src="https://cdn.bootcdn.net/ajax/libs/KaTeX/0.16.6/katex.min.js"></script>
<script defer src="https://cdn.bootcdn.net/ajax/libs/KaTeX/0.16.6/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
</head>

<body>
<div id="header">
<h1 class="title">MPI</h1>
<h3 class="date">2021-07-17</h3>
<div id="TOC">
<ul>
<li><a href="#io" id="toc-io"><span class="toc-section-number">1</span>
I/O</a>
<ul>
<li><a href="#basics" id="toc-basics"><span
class="toc-section-number">1.1</span> Basics</a></li>
<li><a href="#file-view" id="toc-file-view"><span
class="toc-section-number">1.2</span> File View</a></li>
<li><a href="#example" id="toc-example"><span
class="toc-section-number">1.3</span> Example</a></li>
</ul></li>
<li><a href="#derived-datatype" id="toc-derived-datatype"><span
class="toc-section-number">2</span> Derived Datatype</a>
<ul>
<li><a href="#indexed-datatype" id="toc-indexed-datatype"><span
class="toc-section-number">2.1</span> Indexed Datatype</a></li>
</ul></li>
<li><a href="#tips" id="toc-tips"><span
class="toc-section-number">3</span> Tips</a>
<ul>
<li><a href="#run-on-multi-nodes" id="toc-run-on-multi-nodes"><span
class="toc-section-number">3.1</span> Run On Multi Nodes</a></li>
<li><a href="#openmpi-hangs-when" id="toc-openmpi-hangs-when"><span
class="toc-section-number">3.2</span> OpenMPI hangs when</a></li>
<li><a href="#openmpi-pass-environment-variable-to-remote-nodes"
id="toc-openmpi-pass-environment-variable-to-remote-nodes"><span
class="toc-section-number">3.3</span> OpenMPI pass environment variable
to remote nodes</a></li>
</ul></li>
</ul>
</div>
<div id="wrapper">
<h1 data-number="1" id="io"><span class="header-section-number">1</span>
I/O</h1>
<h2 data-number="1.1" id="basics"><span
class="header-section-number">1.1</span> Basics</h2>
<p>The basic things are trivial, including
<code>mpi_file_open, mpi_file_close</code>. Normally, when the file is
opened, we write data into the file using <code>mpi_file_write</code> or
<code>mpi_file_write_at</code>. (<code>mpi_file_write_all</code> or
<code>mpi_file_write_at_all</code> are the collective version.)</p>
<p>Then if we want to write data again, we need to reconfigure the file
pointer or the explicit offset. For the explicit offset, we calculate it
by counting the number of data elements already written. For the file
pointer, we could also explicitly calculate it by counting or use the
procedures <code>mpi_file_get_position</code> and
<code>mpi_file_get_byte_offset</code> combined with explicitly
calculating the starting location of the next write operation.</p>
<p><code>mpi_file_get_position</code> gets the current position of the
individual file pointer in units of etype. The result is
<code>offset</code>. Then we provide <code>offset</code> to
<code>mpi_file_get_byte_offset</code> to convert a view relative
<code>offset</code> (in units of etype) into a displacement in bytes
from the beginning of the file. The result is <code>disp</code>.</p>
<p>Next we could use <code>mpi_file_set_view</code> to change the file
view of the process. Then we could use <code>mpi_file_write_all</code>
for the parallel writing operation. Though
<code>mpi_file_write_all</code> is a blocking function. Note, currently
I am not able to figure out how to use <code>mpi_file_write_at</code>
when the previous write is done by <code>mpi_file_set_view</code> and
<code>mpi_file_write</code>.</p>
<h2 data-number="1.2" id="file-view"><span
class="header-section-number">1.2</span> File View</h2>
<p>A file view is a triplet of arguments
(<code>displacement, etype, filetype</code>) that is passed to
<code>MPI_File_set_view</code>.</p>
<ul>
<li><code>displacement</code> = number of bytes to be skipped from the
start of the file</li>
<li><code>etype</code> = unit of data access (can be any basic or
derived datatype)</li>
<li><code>filetype</code> = specifies layout of etypes within file</li>
</ul>
<figure>
<img src="MPI_fileview.jpg" alt="MPI fileview" />
<figcaption aria-hidden="true">MPI fileview</figcaption>
</figure>
<p>The file view sets the starting location to write by specifying
<code>displacement</code>. The <code>displacement</code> is measured
from the head of the file.</p>
<p>References</p>
<ul>
<li><a href="https://cvw.cac.cornell.edu/ParallelIO/fileviews">Parallel
I/O: File Views</a></li>
<li><a
href="MPI_parallel-io-mpi-io.pdf">MPI_parallel-io-mpi-io.pdf</a></li>
<li><a href="MPI-IO_2017.pdf">MPI-IO_2017.pdf</a></li>
</ul>
<h2 data-number="1.3" id="example"><span
class="header-section-number">1.3</span> Example</h2>
<div class="sourceCode" id="cb1"><pre
class="sourceCode fortran"><code class="sourceCode fortranfixed"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">program</span> io</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">implicit</span> <span class="kw">none</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">continue</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">!</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="kw">call</span> writeBinFile(<span class="dv">2</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">!</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">contains</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">!</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="kw">subroutine</span> writeBinFile(n_write)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">use</span> mpi</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="dt">integer</span>, <span class="dt">intent(in)</span> <span class="dt">::</span> n_write</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="dt">integer</span> ierr, i, myrank, nrank, BUFSIZE, BYTESIZE, thefile</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="dt">parameter</span> (BUFSIZE<span class="kw">=</span><span class="dv">10</span>, BYTESIZE<span class="kw">=</span>BUFSIZE<span class="kw">*</span><span class="dv">4</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="dt">integer</span> buf(BUFSIZE)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="dt">integer(kind=MPI_OFFSET_KIND)</span> disp</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>  <span class="kw">continue</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">call</span> MPI_INIT(ierr)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">call</span> MPI_COMM_RANK(MPI_COMM_WORLD, myrank, ierr)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">call</span> MPI_COMM_SIZE(MPI_COMM_WORLD, nrank, ierr)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">do</span> i <span class="kw">=</span> <span class="dv">0</span>, BUFSIZE</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        buf(i) <span class="kw">=</span> myrank <span class="kw">*</span> BUFSIZE <span class="kw">+</span> myrank</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">end do</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">call</span> MPI_FILE_OPEN(MPI_COMM_WORLD, <span class="st">&#39;mpi_data.bin&#39;</span>, <span class="kw">&amp;</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>                       MPI_MODE_WRONLY <span class="kw">+</span> MPI_MODE_CREATE, <span class="kw">&amp;</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>                       MPI_INFO_NULL, thefile, ierr)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    disp <span class="kw">=</span> myrank <span class="kw">*</span> BYTESIZE</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="co">! 1. Individual file poiner</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    <span class="co">! call MPI_FILE_SET_VIEW(thefile, disp, MPI_INTEGER, &amp;</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    <span class="co">!                        MPI_INTEGER, &#39;native&#39;, &amp;</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    <span class="co">!                        MPI_INFO_NULL, ierr)</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    <span class="co">! call MPI_FILE_WRITE_ALL(thefile, buf, BUFSIZE, MPI_INTEGER, &amp;</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    <span class="co">!                     MPI_STATUS_IGNORE, ierr)</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    <span class="co">! 2. Explicit offset</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>    <span class="kw">call</span> MPI_FILE_WRITE_AT_ALL(thefile, disp, buf, BUFSIZE, MPI_INTEGER,<span class="co"> &amp;</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>                        MPI_STATUS_IGNORE, ierr)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    <span class="kw">if</span> ( n_write <span class="op">&gt;</span> <span class="dv">1</span> ) <span class="kw">then</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>      <span class="co">!</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>      disp <span class="kw">=</span> nrank <span class="kw">*</span> BYTESIZE <span class="kw">+</span> myrank <span class="kw">*</span> BYTESIZE</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>      <span class="co">! 1. Individual file poiner</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>      <span class="co">! call MPI_FILE_SET_VIEW(thefile, disp, MPI_INTEGER, &amp;</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>      <span class="co">!                        MPI_INTEGER, &#39;native&#39;, &amp;</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>      <span class="co">!                        MPI_INFO_NULL, ierr)</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>      <span class="co">! call MPI_FILE_WRITE_ALL(thefile, buf, BUFSIZE, MPI_INTEGER, &amp;</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>      <span class="co">!                     MPI_STATUS_IGNORE, ierr)</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>      <span class="co">! 2. Explicit offset</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>      <span class="kw">call</span> MPI_FILE_WRITE_AT_ALL(thefile, disp, buf, BUFSIZE, MPI_INTEGER, <span class="kw">&amp;</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>                          MPI_STATUS_IGNORE, ierr)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>      <span class="co">!</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>    <span class="kw">end if</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>    <span class="co">!</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>    <span class="kw">call</span> MPI_FILE_CLOSE(thefile, ierr)</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>    <span class="kw">call</span> MPI_FINALIZE(ierr)</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>  <span class="kw">end subroutine</span> writeBinFile</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>  <span class="co">!</span></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a><span class="kw">end program</span></span></code></pre></div>
<p>To write to a file multiple times, we should notice that the starting
location of the write operation must be set again after a write
opeartion. As the above example shows, 2 simple plans for writing twice.
1) 2 times of (<code>MPI_FILE_SET_VIEW</code> +
<code>MPI_FILE_WRITE_ALL</code>) 2) 2 times of
(<code>MPI_FILE_WRITE_AT_ALL</code>). In both plans,
<code>displacement</code> is measured from the head of the file for both
write opeartions. Another hybrid plan is
(<code>MPI_FILE_WRITE_AT_ALL</code>) + (<code>MPI_FILE_SET_VIEW</code> +
<code>MPI_FILE_WRITE_ALL</code>) using the absolute
<code>displacement</code> measured from the head of the file for both
write opeartions. The last hybrid plan is
(<code>MPI_FILE_SET_VIEW</code> + <code>MPI_FILE_WRITE_ALL</code>) +
(<code>MPI_FILE_WRITE_AT_ALL</code>). But it seems like the file view
messes up the displacement for <code>MPI_FILE_WRITE_AT_ALL</code>. I am
not able to figure out how to correctly implement this hybrid plan.</p>
<p>After one write operation, the explicit setting
<code>displacement</code> could be replaced by the procedures as
follows,</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode fortran"><code class="sourceCode fortranfixed"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>disp <span class="kw">=</span> nrank <span class="kw">*</span> BYTESIZE <span class="kw">+</span> myrank <span class="kw">*</span> BYTESIZE</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co">! the following lines give the same disp as the above line</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">call MPI_FILE_GET_POSITION(thefile,offset,ierr)</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">call MPI_FILE_GET_BYTE_OFFSET(thefile,offset,disp,ierr)</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>disp <span class="kw">=</span> disp <span class="kw">+</span> (nrank<span class="kw">-</span><span class="dv">1</span>)<span class="kw">*</span>BYTESIZE</span></code></pre></div>
<p>Since one write operation takes <code>BYTESIZE</code>, it needs to
move the file pointer forward by <code>(nrank-1)*BYTESIZE</code>.</p>
<h1 data-number="2" id="derived-datatype"><span
class="header-section-number">2</span> Derived Datatype</h1>
<h2 data-number="2.1" id="indexed-datatype"><span
class="header-section-number">2.1</span> Indexed Datatype</h2>
<p>The indexed datatype basically includes block offset and block
length. It includes multiple sections of an array to make up of a new
element of the newly created datatype.</p>
<figure>
<img src="MPI_illustration_of_mpi_type_indexed.jpg"
alt="Indexed datatype includes block length and block offset" />
<figcaption aria-hidden="true">Indexed datatype includes block length
and block offset</figcaption>
</figure>
<p>For reference, check P14 in the following attached <a
href="MPI_DataTypes.pdf">MPI DataTypes PDF</a>.</p>
<h1 data-number="3" id="tips"><span
class="header-section-number">3</span> Tips</h1>
<h2 data-number="3.1" id="run-on-multi-nodes"><span
class="header-section-number">3.1</span> Run On Multi Nodes</h2>
<p>In Taicang cluster (太仓集群), we have to use the following commands
to run on multi nodes,</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="ex">mpirun</span> <span class="at">-n</span> 4 <span class="at">-hosts</span> node2,node3 <span class="at">-perhost</span> 2 <span class="at">-env</span> I_MPI_FABRICS tcp ./test</span></code></pre></div>
<h2 data-number="3.2" id="openmpi-hangs-when"><span
class="header-section-number">3.2</span> OpenMPI hangs when</h2>
<p>When the cluster has virtual NIC in addition to the real NIC, OpenMPI
hangs with the default parameter. The reason is that OpenMPI uses tcp to
connect to the wrong NIC, i.e. <code>virbr0</code>. The Taicang cluster
has the real NIC <code>enp97s0f1</code> and <code>virbr0</code>. The
correct command of running OpenMPI across multiple nodes is</p>
<pre><code>mpirun -x LD_LIBRARY_PATH -n 2 -hostfile machine --mca btl_tcp_if_include enp97s0f1 ~/NFS_Project/NFS/relwithdebinfo_gnu/bin/nfs_opt_g nfs.json</code></pre>
<p>The content of the machine file for running 2 procs is</p>
<pre><code>node3 slots=1
node4 slots=1</code></pre>
<p>Reference: <a
href="https://www.open-mpi.org/faq/?category=tcp#tcp-selection">7. How
do I tell Open MPI which IP interfaces / networks to use?</a></p>
<h2 data-number="3.3"
id="openmpi-pass-environment-variable-to-remote-nodes"><span
class="header-section-number">3.3</span> OpenMPI pass environment
variable to remote nodes</h2>
<p>Running NFR code on the remote nodes requires the complete set up of
environment variables. NFR compiled by OpenMPI-4 and gfortran-10.2
requires the loading of <code>libgfortran.so.5</code>. Incomplete set up
of the environment variables results in
<code>error while loading shared libraries: libgfortran.so.5</code>. The
correct command is</p>
<pre><code>mpirun -x LD_LIBRARY_PATH -n 2 -hostfile machine --mca btl_tcp_if_include enp97s0f1 ~/NFS_Project/NFS/relwithdebinfo_gnu/bin/nfs_opt_g nfs.json</code></pre>
</div>
<div class="customHr">.</div>
<footer>
  Created on 2021-07-17 with pandoc
</footer>
</body>
</html>
